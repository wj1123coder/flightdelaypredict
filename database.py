#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç®¡ç†æ¨¡å—
æä¾›JSONæ–‡ä»¶å­˜å‚¨åŠŸèƒ½
"""

import os
import json
import sqlite3
from datetime import datetime
from typing import List, Dict, Any, Optional

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_type: str = 'json'):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_type: æ•°æ®åº“ç±»å‹ï¼Œ'json' æˆ– 'sqlite'
        """
        self.db_type = db_type
        self.data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        
        if db_type == 'sqlite':
            self.db_path = os.path.join(self.data_dir, 'flight_delay.db')
            self._init_sqlite_db()
        else:
            self.history_file = os.path.join(self.data_dir, 'prediction_history.json')
            self.stats_file = os.path.join(self.data_dir, 'system_stats.json')
    
    def _init_sqlite_db(self):
        """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
        if not os.path.exists(self.db_path):
            print(f"ğŸ“¦ åˆ›å»ºSQLiteæ•°æ®åº“: {self.db_path}")
            self._create_tables()
    
    def _create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # é¢„æµ‹å†å²è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                airline TEXT NOT NULL,
                flight_number TEXT NOT NULL,
                origin TEXT NOT NULL,
                destination TEXT NOT NULL,
                departure_date TEXT NOT NULL,
                departure_time TEXT NOT NULL,
                delay_probability REAL NOT NULL,
                estimated_delay INTEGER NOT NULL,
                risk_level TEXT NOT NULL,
                confidence REAL NOT NULL,
                model_used TEXT NOT NULL,
                user_ip TEXT,
                metadata TEXT
            )
        ''')
        
        # ç³»ç»Ÿç»Ÿè®¡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date TEXT NOT NULL,
                total_predictions INTEGER DEFAULT 0,
                total_delayed INTEGER DEFAULT 0,
                total_on_time INTEGER DEFAULT 0,
                avg_delay_probability REAL DEFAULT 0,
                most_predicted_airline TEXT,
                most_predicted_route TEXT,
                peak_hour TEXT
            )
        ''')
        
        # ç”¨æˆ·åé¦ˆè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                prediction_id INTEGER,
                timestamp TEXT NOT NULL,
                flight_number TEXT,
                actual_delay INTEGER,
                accuracy_rating INTEGER,
                comments TEXT,
                user_ip TEXT,
                FOREIGN KEY (prediction_id) REFERENCES predictions (id)
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def save_prediction(self, flight_data: Dict[str, Any], 
                       prediction: Dict[str, Any],
                       user_ip: str = None,
                       metadata: Dict[str, Any] = None) -> Optional[int]:
        """
        ä¿å­˜é¢„æµ‹è®°å½•
        
        Args:
            flight_data: èˆªç­æ•°æ®
            prediction: é¢„æµ‹ç»“æœ
            user_ip: ç”¨æˆ·IPåœ°å€
            metadata: é¢å¤–å…ƒæ•°æ®
            
        Returns:
            è®°å½•IDæˆ–None
        """
        if self.db_type == 'sqlite':
            return self._save_to_sqlite(flight_data, prediction, user_ip, metadata)
        else:
            return self._save_to_json(flight_data, prediction, user_ip, metadata)
    
    def _save_to_sqlite(self, flight_data, prediction, user_ip, metadata):
        """ä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO predictions 
                (timestamp, airline, flight_number, origin, destination, 
                 departure_date, departure_time, delay_probability, 
                 estimated_delay, risk_level, confidence, model_used, user_ip, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                datetime.now().isoformat(),
                flight_data.get('airline', ''),
                flight_data.get('flight_number', ''),
                flight_data.get('origin', ''),
                flight_data.get('destination', ''),
                flight_data.get('departure_date', ''),
                flight_data.get('departure_time', ''),
                prediction.get('delay_probability', 0),
                prediction.get('estimated_delay_minutes', 0),
                prediction.get('risk_level', 'ä½'),
                prediction.get('confidence', 0.5),
                prediction.get('model_used', 'è§„åˆ™å¼•æ“'),
                user_ip,
                json.dumps(metadata) if metadata else None
            ))
            
            record_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_daily_stats()
            
            print(f"âœ… SQLiteè®°å½•ä¿å­˜æˆåŠŸï¼ŒID: {record_id}")
            return record_id
            
        except Exception as e:
            print(f"âŒ SQLiteä¿å­˜å¤±è´¥: {e}")
            return None
    
    def _save_to_json(self, flight_data, prediction, user_ip, metadata):
        """ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰å†å²
            history = self.load_history()
            
            # åˆ›å»ºæ–°è®°å½•
            record = {
                "id": len(history) + 1,
                "timestamp": datetime.now().isoformat(),
                "flight_data": flight_data,
                "prediction": prediction,
                "user_ip": user_ip or "127.0.0.1",
                "metadata": metadata or {}
            }
            
            # æ·»åŠ åˆ°å†å²
            history.append(record)
            
            # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(history) > 1000:
                history = history[-1000:]
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_json_stats(record)
            
            print(f"âœ… JSONè®°å½•ä¿å­˜æˆåŠŸï¼ŒID: {record['id']}")
            return record['id']
            
        except Exception as e:
            print(f"âŒ JSONä¿å­˜å¤±è´¥: {e}")
            return None
    
    def load_history(self, limit: int = None) -> List[Dict]:
        """åŠ è½½é¢„æµ‹å†å²"""
        if self.db_type == 'sqlite':
            return self._load_from_sqlite(limit)
        else:
            return self._load_from_json(limit)
    
    def _load_from_sqlite(self, limit):
        """ä»SQLiteåŠ è½½"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            query = '''
                SELECT * FROM predictions 
                ORDER BY timestamp DESC
            '''
            if limit:
                query += f' LIMIT {limit}'
            
            cursor.execute(query)
            rows = cursor.fetchall()
            conn.close()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            history = []
            for row in rows:
                record = dict(row)
                # è§£æmetadata
                if record.get('metadata'):
                    record['metadata'] = json.loads(record['metadata'])
                history.append(record)
            
            return history
            
        except Exception as e:
            print(f"âŒ SQLiteåŠ è½½å¤±è´¥: {e}")
            return []
    
    def _load_from_json(self, limit):
        """ä»JSONæ–‡ä»¶åŠ è½½"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                
                # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
                history.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
                
                return history[:limit] if limit else history
        except:
            pass
        return []
    
    def get_recent_predictions(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„é¢„æµ‹è®°å½•"""
        return self.load_history(limit)
    
    def get_today_stats(self) -> Dict[str, Any]:
        """è·å–ä»Šæ—¥ç»Ÿè®¡"""
        today = datetime.now().date().isoformat()
        
        if self.db_type == 'sqlite':
            return self._get_sqlite_today_stats(today)
        else:
            return self._get_json_today_stats(today)
    
    def _get_sqlite_today_stats(self, today):
        """ä»SQLiteè·å–ä»Šæ—¥ç»Ÿè®¡"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ä»Šæ—¥é¢„æµ‹æ€»æ•°
            cursor.execute('''
                SELECT COUNT(*) FROM predictions 
                WHERE date(timestamp) = ?
            ''', (today,))
            total = cursor.fetchone()[0]
            
            # å»¶è¯¯é¢„æµ‹æ•°
            cursor.execute('''
                SELECT COUNT(*) FROM predictions 
                WHERE date(timestamp) = ? AND delay_probability > 0.5
            ''', (today,))
            delayed = cursor.fetchone()[0]
            
            # å¹³å‡å»¶è¯¯æ¦‚ç‡
            cursor.execute('''
                SELECT AVG(delay_probability) FROM predictions 
                WHERE date(timestamp) = ?
            ''', (today,))
            avg_prob = cursor.fetchone()[0] or 0
            
            conn.close()
            
            return {
                'date': today,
                'total': total,
                'delayed': delayed,
                'on_time': total - delayed,
                'avg_delay_prob': round(avg_prob, 3)
            }
            
        except Exception as e:
            print(f"âŒ è·å–SQLiteç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'date': today,
                'total': 0,
                'delayed': 0,
                'on_time': 0,
                'avg_delay_prob': 0
            }
    
    def _get_json_today_stats(self, today):
        """ä»JSONè·å–ä»Šæ—¥ç»Ÿè®¡"""
        history = self.load_history()
        
        # ç­›é€‰ä»Šæ—¥è®°å½•
        today_predictions = [
            p for p in history 
            if p.get('timestamp', '').startswith(today)
        ]
        
        # ç»Ÿè®¡
        delayed_count = len([
            p for p in today_predictions 
            if p.get('prediction', {}).get('delay_probability', 0) > 0.5
        ])
        
        total = len(today_predictions)
        avg_prob = sum(
            p.get('prediction', {}).get('delay_probability', 0) 
            for p in today_predictions
        ) / max(total, 1)
        
        return {
            'date': today,
            'total': total,
            'delayed': delayed_count,
            'on_time': total - delayed_count,
            'avg_delay_prob': round(avg_prob, 3)
        }
    
    def _update_daily_stats(self):
        """æ›´æ–°æ¯æ—¥ç»Ÿè®¡ï¼ˆSQLiteï¼‰"""
        if self.db_type != 'sqlite':
            return
        
        today = datetime.now().date().isoformat()
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥ä»Šæ—¥ç»Ÿè®¡æ˜¯å¦å­˜åœ¨
            cursor.execute('SELECT id FROM statistics WHERE date = ?', (today,))
            exists = cursor.fetchone()
            
            # è·å–ä»Šæ—¥æ•°æ®
            stats = self._get_sqlite_today_stats(today)
            
            if exists:
                # æ›´æ–°ç°æœ‰è®°å½•
                cursor.execute('''
                    UPDATE statistics SET 
                    total_predictions = ?,
                    total_delayed = ?,
                    total_on_time = ?,
                    avg_delay_probability = ?
                    WHERE date = ?
                ''', (
                    stats['total'],
                    stats['delayed'],
                    stats['on_time'],
                    stats['avg_delay_prob'],
                    today
                ))
            else:
                # æ’å…¥æ–°è®°å½•
                cursor.execute('''
                    INSERT INTO statistics 
                    (date, total_predictions, total_delayed, 
                     total_on_time, avg_delay_probability)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    today,
                    stats['total'],
                    stats['delayed'],
                    stats['on_time'],
                    stats['avg_delay_prob']
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âŒ æ›´æ–°æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _update_json_stats(self, new_record):
        """æ›´æ–°JSONç»Ÿè®¡"""
        try:
            # åŠ è½½ç°æœ‰ç»Ÿè®¡
            if os.path.exists(self.stats_file):
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
            else:
                stats = {}
            
            today = datetime.now().date().isoformat()
            
            # è·å–ä»Šæ—¥ç»Ÿè®¡
            today_stats = self._get_json_today_stats(today)
            
            # æ›´æ–°ç»Ÿè®¡
            stats[today] = today_stats
            
            # åªä¿ç•™æœ€è¿‘30å¤©çš„ç»Ÿè®¡
            dates = list(stats.keys())
            dates.sort(reverse=True)
            if len(dates) > 30:
                for old_date in dates[30:]:
                    del stats[old_date]
            
            # ä¿å­˜ç»Ÿè®¡æ–‡ä»¶
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            
        except Exception as e:
            print(f"âŒ æ›´æ–°JSONç»Ÿè®¡å¤±è´¥: {e}")
    
    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡"""
        if self.db_type == 'sqlite':
            return self._get_sqlite_system_stats()
        else:
            return self._get_json_system_stats()
    
    def _get_sqlite_system_stats(self):
        """è·å–SQLiteç³»ç»Ÿç»Ÿè®¡"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ€»é¢„æµ‹æ•°
            cursor.execute('SELECT COUNT(*) FROM predictions')
            total = cursor.fetchone()[0]
            
            # æ€»å»¶è¯¯é¢„æµ‹æ•°
            cursor.execute('SELECT COUNT(*) FROM predictions WHERE delay_probability > 0.5')
            total_delayed = cursor.fetchone()[0]
            
            # å¹³å‡å»¶è¯¯æ¦‚ç‡
            cursor.execute('SELECT AVG(delay_probability) FROM predictions')
            avg_prob = cursor.fetchone()[0] or 0
            
            # æœ€å¸¸é¢„æµ‹çš„èˆªç©ºå…¬å¸
            cursor.execute('''
                SELECT airline, COUNT(*) as count 
                FROM predictions 
                GROUP BY airline 
                ORDER BY count DESC 
                LIMIT 3
            ''')
            top_airlines = [{'airline': row[0], 'count': row[1]} for row in cursor.fetchall()]
            
            # æœ€å¸¸é¢„æµ‹çš„èˆªçº¿
            cursor.execute('''
                SELECT origin, destination, COUNT(*) as count 
                FROM predictions 
                GROUP BY origin, destination 
                ORDER BY count DESC 
                LIMIT 5
            ''')
            top_routes = [{'route': f"{row[0]}-{row[1]}", 'count': row[2]} for row in cursor.fetchall()]
            
            conn.close()
            
            return {
                'total_predictions': total,
                'total_delayed': total_delayed,
                'total_on_time': total - total_delayed,
                'avg_delay_probability': round(avg_prob, 3),
                'top_airlines': top_airlines,
                'top_routes': top_routes,
                'database_type': 'sqlite'
            }
            
        except Exception as e:
            print(f"âŒ è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {e}")
            return self._get_default_stats()
    
    def _get_json_system_stats(self):
        """è·å–JSONç³»ç»Ÿç»Ÿè®¡"""
        history = self.load_history()
        
        if not history:
            return self._get_default_stats()
        
        total = len(history)
        total_delayed = len([
            p for p in history 
            if p.get('prediction', {}).get('delay_probability', 0) > 0.5
        ])
        avg_prob = sum(
            p.get('prediction', {}).get('delay_probability', 0) 
            for p in history
        ) / max(total, 1)
        
        # ç»Ÿè®¡èˆªç©ºå…¬å¸
        airline_counts = {}
        route_counts = {}
        
        for record in history:
            flight_data = record.get('flight_data', {})
            airline = flight_data.get('airline', 'æœªçŸ¥')
            origin = flight_data.get('origin', '')
            destination = flight_data.get('destination', '')
            
            airline_counts[airline] = airline_counts.get(airline, 0) + 1
            
            if origin and destination:
                route = f"{origin}-{destination}"
                route_counts[route] = route_counts.get(route, 0) + 1
        
        # æ’åº
        top_airlines = sorted(
            [{'airline': k, 'count': v} for k, v in airline_counts.items()],
            key=lambda x: x['count'], reverse=True
        )[:3]
        
        top_routes = sorted(
            [{'route': k, 'count': v} for k, v in route_counts.items()],
            key=lambda x: x['count'], reverse=True
        )[:5]
        
        return {
            'total_predictions': total,
            'total_delayed': total_delayed,
            'total_on_time': total - total_delayed,
            'avg_delay_probability': round(avg_prob, 3),
            'top_airlines': top_airlines,
            'top_routes': top_routes,
            'database_type': 'json'
        }
    
    def _get_default_stats(self):
        """è·å–é»˜è®¤ç»Ÿè®¡"""
        return {
            'total_predictions': 0,
            'total_delayed': 0,
            'total_on_time': 0,
            'avg_delay_probability': 0,
            'top_airlines': [],
            'top_routes': [],
            'database_type': self.db_type
        }
    
    def save_feedback(self, prediction_id: int, 
                     actual_delay: int, 
                     accuracy_rating: int,
                     comments: str = None,
                     user_ip: str = None) -> bool:
        """ä¿å­˜ç”¨æˆ·åé¦ˆ"""
        try:
            if self.db_type == 'sqlite':
                return self._save_feedback_sqlite(prediction_id, actual_delay, 
                                                 accuracy_rating, comments, user_ip)
            else:
                return self._save_feedback_json(prediction_id, actual_delay,
                                               accuracy_rating, comments, user_ip)
        except Exception as e:
            print(f"âŒ ä¿å­˜åé¦ˆå¤±è´¥: {e}")
            return False
    
    def _save_feedback_sqlite(self, prediction_id, actual_delay, 
                             accuracy_rating, comments, user_ip):
        """ä¿å­˜åé¦ˆåˆ°SQLite"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–èˆªç­å·
            cursor.execute('SELECT flight_number FROM predictions WHERE id = ?', (prediction_id,))
            result = cursor.fetchone()
            flight_number = result[0] if result else None
            
            cursor.execute('''
                INSERT INTO feedback 
                (prediction_id, timestamp, flight_number, actual_delay, 
                 accuracy_rating, comments, user_ip)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                prediction_id,
                datetime.now().isoformat(),
                flight_number,
                actual_delay,
                accuracy_rating,
                comments,
                user_ip
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"âŒ SQLiteåé¦ˆä¿å­˜å¤±è´¥: {e}")
            return False
    
    def _save_feedback_json(self, prediction_id, actual_delay, 
                           accuracy_rating, comments, user_ip):
        """ä¿å­˜åé¦ˆåˆ°JSON"""
        try:
            feedback_file = os.path.join(self.data_dir, 'user_feedback.json')
            
            # è¯»å–ç°æœ‰åé¦ˆ
            if os.path.exists(feedback_file):
                with open(feedback_file, 'r', encoding='utf-8') as f:
                    feedbacks = json.load(f)
            else:
                feedbacks = []
            
            # åˆ›å»ºæ–°åé¦ˆ
            feedback = {
                "id": len(feedbacks) + 1,
                "prediction_id": prediction_id,
                "timestamp": datetime.now().isoformat(),
                "actual_delay": actual_delay,
                "accuracy_rating": accuracy_rating,
                "comments": comments,
                "user_ip": user_ip
            }
            
            feedbacks.append(feedback)
            
            # ä¿å­˜
            with open(feedback_file, 'w', encoding='utf-8') as f:
                json.dump(feedbacks, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            print(f"âŒ JSONåé¦ˆä¿å­˜å¤±è´¥: {e}")
            return False
    
    def export_data(self, export_type: str = 'json') -> str:
        """å¯¼å‡ºæ•°æ®"""
        try:
            if export_type == 'json':
                return self._export_json()
            elif export_type == 'csv':
                return self._export_csv()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºç±»å‹: {export_type}")
        except Exception as e:
            print(f"âŒ æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            return ""
    
    def _export_json(self) -> str:
        """å¯¼å‡ºä¸ºJSON"""
        history = self.load_history()
        stats = self.get_system_stats()
        
        export_data = {
            "metadata": {
                "export_date": datetime.now().isoformat(),
                "total_records": len(history),
                "database_type": self.db_type
            },
            "statistics": stats,
            "history": history
        }
        
        export_file = os.path.join(self.data_dir, f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(export_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return export_file
    
    def _export_csv(self) -> str:
        """å¯¼å‡ºä¸ºCSV"""
        import csv
        
        history = self.load_history()
        if not history:
            return ""
        
        export_file = os.path.join(self.data_dir, f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
        
        # æå–æ‰€æœ‰å¯èƒ½çš„å­—æ®µ
        fieldnames = set()
        for record in history:
            # åŸºæœ¬å­—æ®µ
            fieldnames.update(['id', 'timestamp'])
            # èˆªç­æ•°æ®å­—æ®µ
            if 'flight_data' in record:
                fieldnames.update([f"flight_{k}" for k in record['flight_data'].keys()])
            # é¢„æµ‹å­—æ®µ
            if 'prediction' in record:
                fieldnames.update([f"prediction_{k}" for k in record['prediction'].keys()])
        
        fieldnames = list(fieldnames)
        fieldnames.sort()
        
        with open(export_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for record in history:
                row = {'id': record.get('id'), 'timestamp': record.get('timestamp')}
                
                # æ·»åŠ èˆªç­æ•°æ®
                flight_data = record.get('flight_data', {})
                for k, v in flight_data.items():
                    row[f"flight_{k}"] = v
                
                # æ·»åŠ é¢„æµ‹æ•°æ®
                prediction = record.get('prediction', {})
                for k, v in prediction.items():
                    if isinstance(v, (dict, list)):
                        row[f"prediction_{k}"] = json.dumps(v, ensure_ascii=False)
                    else:
                        row[f"prediction_{k}"] = v
                
                writer.writerow(row)
        
        return export_file
    
    def cleanup_old_data(self, days: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            cutoff_date = (datetime.now() - timedelta(days=days)).date().isoformat()
            
            if self.db_type == 'sqlite':
                self._cleanup_sqlite(cutoff_date)
            else:
                self._cleanup_json(cutoff_date)
            
            print(f"âœ… æ¸…ç†{days}å¤©å‰çš„æ•°æ®å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥: {e}")
    
    def _cleanup_sqlite(self, cutoff_date):
        """æ¸…ç†SQLiteæ—§æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ é™¤æ—§é¢„æµ‹è®°å½•
        cursor.execute('DELETE FROM predictions WHERE date(timestamp) < ?', (cutoff_date,))
        deleted_count = cursor.rowcount
        
        # åˆ é™¤å…³è”çš„åé¦ˆ
        cursor.execute('''
            DELETE FROM feedback 
            WHERE prediction_id IN (
                SELECT id FROM predictions WHERE date(timestamp) < ?
            )
        ''', (cutoff_date,))
        
        # åˆ é™¤æ—§ç»Ÿè®¡
        cursor.execute('DELETE FROM statistics WHERE date < ?', (cutoff_date,))
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ“Š æ¸…ç†SQLiteæ•°æ®: åˆ é™¤{deleted_count}æ¡é¢„æµ‹è®°å½•")
    
    def _cleanup_json(self, cutoff_date):
        """æ¸…ç†JSONæ—§æ•°æ®"""
        # æ¸…ç†é¢„æµ‹å†å²
        if os.path.exists(self.history_file):
            with open(self.history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
            
            new_history = [
                record for record in history 
                if record.get('timestamp', '').split('T')[0] >= cutoff_date
            ]
            
            deleted_count = len(history) - len(new_history)
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(new_history, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š æ¸…ç†JSONæ•°æ®: åˆ é™¤{deleted_count}æ¡é¢„æµ‹è®°å½•")
        
        # æ¸…ç†ç»Ÿè®¡æ–‡ä»¶
        if os.path.exists(self.stats_file):
            with open(self.stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
            
            new_stats = {
                k: v for k, v in stats.items() 
                if k >= cutoff_date
            }
            
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(new_stats, f, ensure_ascii=False, indent=2)

# åˆ›å»ºå…¨å±€å®ä¾‹
db_manager = DatabaseManager(db_type='json')  # é»˜è®¤ä½¿ç”¨JSONå­˜å‚¨

if __name__ == '__main__':
    # æµ‹è¯•æ•°æ®åº“åŠŸèƒ½
    print("ğŸ§ª æµ‹è¯•æ•°æ®åº“åŠŸèƒ½...")
    
    # æµ‹è¯•æ•°æ®
    test_flight_data = {
        'airline': 'CA',
        'flight_number': 'CA1234',
        'origin': 'PEK',
        'destination': 'PVG',
        'departure_date': '2024-01-15',
        'departure_time': '14:30'
    }
    
    test_prediction = {
        'delay_probability': 0.65,
        'estimated_delay_minutes': 45,
        'risk_level': 'é«˜',
        'confidence': 0.85,
        'model_used': 'è§„åˆ™å¼•æ“'
    }
    
    # ä¿å­˜æµ‹è¯•è®°å½•
    record_id = db_manager.save_prediction(test_flight_data, test_prediction)
    print(f"ğŸ“ ä¿å­˜è®°å½•æˆåŠŸï¼ŒID: {record_id}")
    
    # åŠ è½½å†å²è®°å½•
    history = db_manager.get_recent_predictions(5)
    print(f"ğŸ“Š æœ€è¿‘5æ¡è®°å½•: {len(history)} æ¡")
    
    # è·å–ä»Šæ—¥ç»Ÿè®¡
    today_stats = db_manager.get_today_stats()
    print(f"ğŸ“ˆ ä»Šæ—¥ç»Ÿè®¡: {today_stats}")
    
    # è·å–ç³»ç»Ÿç»Ÿè®¡
    system_stats = db_manager.get_system_stats()
    print(f"ğŸ¢ ç³»ç»Ÿç»Ÿè®¡: {system_stats['total_predictions']} æ¡æ€»è®°å½•")
    
    print("âœ… æ•°æ®åº“æµ‹è¯•å®Œæˆ")